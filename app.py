import streamlit as st
import httpx
import os
from dotenv import load_dotenv

load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

st.set_page_config(page_title="Gerador de Quest√µes AWS", layout="centered")

st.markdown("## üöÄ Gerador de Quest√µes AWS")
st.markdown("Responda cada quest√£o, veja o feedback e finalize para ver seu desempenho geral.")

if "questoes" not in st.session_state:
    st.session_state.questoes = []
if "respostas" not in st.session_state:
    st.session_state.respostas = []
if "avaliacoes" not in st.session_state:
    st.session_state.avaliacoes = []
if "certificacao" not in st.session_state:
    st.session_state.certificacao = "developer"

CERT_MAP = {
    "Developer Associate": "developer",
    "Architect Associate": "saa",
    "Architect Professional": "sap",
    "Cloud Practitioner": "clf",
    "AI Practitioner": "aip"
}

def carregar_base_por_cert(cert_id):
    caminho = f"base/base_{cert_id}.txt"
    try:
        with open(caminho, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return "Sem base para essa certifica√ß√£o."

def gerar_questao(certificacao_friendly):
    cert_id = CERT_MAP.get(certificacao_friendly, "clf")
    base = carregar_base_por_cert(cert_id)
    prompt = f"""
    Voc√™ √© um especialista em criar quest√µes no estilo da prova oficial AWS {certificacao_friendly}.
    Com base nas quest√µes abaixo (que representam o estilo e conte√∫do esperados), crie uma nova quest√£o.
    
    Base de inspira√ß√£o:
    {base}
    
    Regras:
    - Utilize um cen√°rio realista com linguagem t√©cnica
    - Siga o estilo de m√∫ltipla escolha
    - Crie 4 alternativas (A, B, C, D)
    - N√£o inclua a resposta correta
    - N√£o adicione explica√ß√µes, coment√°rios ou links
    - Seja direto e preciso como uma quest√£o de prova
    
    Formato:
    Pergunta:
    [enunciado da quest√£o]
    
    Op√ß√µes:
    A) ...
    B) ...
    C) ...
    D) ...
    """
    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "llama-3.3-70b-versatile",
        "messages": [{"role": "user", "content": prompt}]
    }

    try:
        with httpx.Client() as client:
            response = client.post("https://api.groq.com/openai/v1/chat/completions", json=payload, headers=headers)
            response.raise_for_status()
            return response.json()["choices"][0]["message"]["content"]
    except Exception as e:
        return f"Erro: {str(e)}"

def avaliar_questao(certificacao_friendly, pergunta, resposta_usuario):
    prompt = f"""
    Voc√™ √© um avaliador experiente de quest√µes de certifica√ß√µes AWS, como a {certificacao_friendly}.
    Com base na quest√£o abaixo e na resposta fornecida, realize uma an√°lise t√©cnica objetiva.
    
    Quest√£o:
    {pergunta}
    
    Resposta do usu√°rio: {resposta_usuario}
    
    Sua tarefa:
    1. Informe se a resposta est√° correta ou incorreta.
    2. Aponte qual √© a alternativa correta.
    3. Explique tecnicamente por que essa alternativa √© a correta, com base nas boas pr√°ticas da AWS.
    4. Diga por que as outras alternativas est√£o incorretas.
    5. Inclua links oficiais da AWS relevantes no final, em Markdown.
    
    Mantenha o estilo formal e direto como esperado em provas oficiais e materiais t√©cnicos.
    """
    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "llama3-70b-8192",
        "messages": [{"role": "user", "content": prompt}]
    }

    try:
        with httpx.Client() as client:
            response = client.post("https://api.groq.com/openai/v1/chat/completions", json=payload, headers=headers)
            response.raise_for_status()
            return response.json()["choices"][0]["message"]["content"]
    except Exception as e:
        return f"Erro ao avaliar: {e}"

st.session_state.certificacao = st.selectbox("üìò Escolha a certifica√ß√£o:", list(CERT_MAP.keys()))

if st.button("‚ûï Gerar nova quest√£o"):
    questao = gerar_questao(st.session_state.certificacao)
    st.session_state.questoes.append(questao)
    st.session_state.respostas.append(None)
    st.session_state.avaliacoes.append("")

for idx, q in enumerate(st.session_state.questoes):
    st.markdown(f"### Quest√£o {idx + 1}")
    st.text_area("üìÑ Enunciado e Op√ß√µes:", value=q, key=f"q_{idx}", height=250, disabled=True)

    resposta = st.radio(
        f"Sua resposta (Q{idx+1}):",
        ["A", "B", "C", "D"],
        index=0 if not st.session_state.respostas[idx] else ["A", "B", "C", "D"].index(st.session_state.respostas[idx]),
        key=f"resp_{idx}"
    )
    if st.button(f"‚úÖ Avaliar Resposta {idx + 1}"):
        st.session_state.respostas[idx] = resposta
        resultado = avaliar_questao(st.session_state.certificacao, q, resposta)
        st.session_state.avaliacoes[idx] = resultado

    if st.session_state.avaliacoes[idx]:
        st.markdown("**üîç Avalia√ß√£o:**")
        st.markdown(st.session_state.avaliacoes[idx])

if st.button("üìä Finalizar e Ver Desempenho Geral"):
    st.markdown("---")
    acertos = sum("‚úîÔ∏è Correta" in av or "‚úÖ Correta" in av for av in st.session_state.avaliacoes if av)
    total = len([a for a in st.session_state.avaliacoes if a])
    st.markdown(f"### üéØ Resultado Final: {acertos}/{total} acertos")
